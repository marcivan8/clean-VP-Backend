// utils/sceneAnalyzer.js - Analyse des objets et sc√®nes avec GPT-4o-mini-vision
const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');

let openai = null;

/**
 * Initialise le client OpenAI
 */
function initializeOpenAI() {
  if (!openai && process.env.OPENAI_API_KEY) {
    openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
    console.log('‚úÖ OpenAI client initialis√© pour analyse visuelle');
  }
  return openai;
}

/**
 * Analyse une image avec GPT-4o-mini-vision pour d√©tecter objets et sc√®nes
 * @param {string} imagePath - Chemin vers l'image
 * @param {string} language - Langue pour la r√©ponse (d√©faut: 'en')
 * @returns {Promise<Object>} - R√©sultats de l'analyse
 */
async function analyzeScene(imagePath, language = 'en') {
  try {
    const client = initializeOpenAI();
    
    if (!client) {
      throw new Error('OpenAI client non initialis√©. V√©rifiez OPENAI_API_KEY.');
    }

    if (!fs.existsSync(imagePath)) {
      throw new Error(`Image non trouv√©e: ${imagePath}`);
    }

    // Lire l'image en base64
    const imageBuffer = fs.readFileSync(imagePath);
    const base64Image = imageBuffer.toString('base64');
    const mimeType = path.extname(imagePath).toLowerCase() === '.png' ? 'image/png' : 'image/jpeg';

    // Prompts selon la langue
    const prompts = {
      en: `Analyze this video frame and provide a detailed description of:
1. Objects present in the scene (list all visible objects)
2. Scene type and context (indoor/outdoor, setting, environment)
3. Visual elements (colors, lighting, composition)
4. Activity or action happening (if any)
5. Overall mood and atmosphere

Format your response as a JSON object with the following structure:
{
  "objects": ["object1", "object2", ...],
  "sceneType": "description",
  "environment": "indoor/outdoor description",
  "visualElements": {
    "colors": ["color1", "color2"],
    "lighting": "description",
    "composition": "description"
  },
  "activity": "description or null",
  "mood": "description",
  "tags": ["tag1", "tag2", ...]
}`,
      fr: `Analysez cette frame vid√©o et fournissez une description d√©taill√©e de:
1. Objets pr√©sents dans la sc√®ne (listez tous les objets visibles)
2. Type de sc√®ne et contexte (int√©rieur/ext√©rieur, cadre, environnement)
3. √âl√©ments visuels (couleurs, √©clairage, composition)
4. Activit√© ou action en cours (si applicable)
5. Ambiance et atmosph√®re g√©n√©rale

Formatez votre r√©ponse comme un objet JSON avec la structure suivante:
{
  "objects": ["objet1", "objet2", ...],
  "sceneType": "description",
  "environment": "description int√©rieur/ext√©rieur",
  "visualElements": {
    "colors": ["couleur1", "couleur2"],
    "lighting": "description",
    "composition": "description"
  },
  "activity": "description ou null",
  "mood": "description",
  "tags": ["tag1", "tag2", ...]
}`,
      tr: `Bu video karesini analiz edin ve ≈üunlarƒ±n detaylƒ± bir a√ßƒ±klamasƒ±nƒ± saƒülayƒ±n:
1. Sahnede bulunan nesneler (t√ºm g√∂r√ºn√ºr nesneleri listeleyin)
2. Sahne t√ºr√º ve baƒülam (i√ß mekan/dƒ±≈ü mekan, ortam, √ßevre)
3. G√∂rsel √∂ƒüeler (renkler, aydƒ±nlatma, kompozisyon)
4. Ger√ßekle≈üen aktivite veya eylem (varsa)
5. Genel ruh hali ve atmosfer

Yanƒ±tƒ±nƒ±zƒ± a≈üaƒüƒ±daki yapƒ±ya sahip bir JSON nesnesi olarak bi√ßimlendirin:
{
  "objects": ["nesne1", "nesne2", ...],
  "sceneType": "a√ßƒ±klama",
  "environment": "i√ß mekan/dƒ±≈ü mekan a√ßƒ±klamasƒ±",
  "visualElements": {
    "colors": ["renk1", "renk2"],
    "lighting": "a√ßƒ±klama",
    "composition": "a√ßƒ±klama"
  },
  "activity": "a√ßƒ±klama veya null",
  "mood": "a√ßƒ±klama",
  "tags": ["etiket1", "etiket2", ...]
}`
    };

    const prompt = prompts[language] || prompts.en;

    console.log(`üîç Analyse de sc√®ne avec GPT-4o-mini-vision: ${imagePath}`);

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: prompt
            },
            {
              type: "image_url",
              image_url: {
                url: `data:${mimeType};base64,${base64Image}`
              }
            }
          ]
        }
      ],
      max_tokens: 1000,
      temperature: 0.3
    });

    const content = response.choices[0]?.message?.content || '';
    
    // Essayer de parser le JSON de la r√©ponse
    let analysisResult;
    try {
      // Extraire le JSON de la r√©ponse (peut √™tre entour√© de markdown)
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        analysisResult = JSON.parse(jsonMatch[0]);
      } else {
        // Fallback: cr√©er un objet √† partir du texte
        analysisResult = {
          rawDescription: content,
          objects: extractObjectsFromText(content),
          sceneType: extractSceneType(content),
          environment: extractEnvironment(content),
          tags: extractTags(content)
        };
      }
    } catch (parseError) {
      console.warn('‚ö†Ô∏è Impossible de parser JSON, utilisation du texte brut');
      analysisResult = {
        rawDescription: content,
        objects: extractObjectsFromText(content),
        sceneType: extractSceneType(content),
        environment: extractEnvironment(content),
        tags: extractTags(content)
      };
    }

    return {
      success: true,
      analysis: analysisResult,
      model: 'gpt-4o-mini',
      timestamp: new Date().toISOString()
    };

  } catch (error) {
    console.error('‚ùå Erreur analyse sc√®ne:', error);
    return {
      success: false,
      error: error.message,
      analysis: null
    };
  }
}

/**
 * Analyse plusieurs frames et agr√®ge les r√©sultats
 * @param {string[]} framePaths - Chemins vers les frames
 * @param {string} language - Langue pour la r√©ponse
 * @returns {Promise<Object>} - R√©sultats agr√©g√©s
 */
async function analyzeScenesBatch(framePaths, language = 'en') {
  const results = [];
  
  // Limiter √† 5 frames pour √©viter les co√ªts excessifs
  const framesToAnalyze = framePaths.slice(0, 5);
  
  for (const framePath of framesToAnalyze) {
    try {
      const result = await analyzeScene(framePath, language);
      if (result.success) {
        results.push(result);
      }
      // Petite pause pour √©viter les rate limits
      await new Promise(resolve => setTimeout(resolve, 500));
    } catch (error) {
      console.error(`Erreur analyse frame ${framePath}:`, error);
    }
  }

  // Agr√©ger les r√©sultats
  const allObjects = new Set();
  const allTags = new Set();
  const sceneTypes = [];
  const environments = [];

  results.forEach(r => {
    if (r.analysis) {
      if (r.analysis.objects) {
        r.analysis.objects.forEach(obj => allObjects.add(obj));
      }
      if (r.analysis.tags) {
        r.analysis.tags.forEach(tag => allTags.add(tag));
      }
      if (r.analysis.sceneType) {
        sceneTypes.push(r.analysis.sceneType);
      }
      if (r.analysis.environment) {
        environments.push(r.analysis.environment);
      }
    }
  });

  return {
    framesAnalyzed: results.length,
    results: results,
    aggregated: {
      allObjects: Array.from(allObjects),
      allTags: Array.from(allTags),
      commonSceneTypes: sceneTypes,
      environments: [...new Set(environments)],
      dominantEnvironment: environments[0] || null
    }
  };
}

// Fonctions helper pour extraire des informations du texte
function extractObjectsFromText(text) {
  const objectKeywords = ['object', 'item', 'thing', 'objet', '√©l√©ment', 'nesne', 'e≈üya'];
  // Logique simplifi√©e - dans un vrai cas, on utiliserait un parsing plus sophistiqu√©
  return [];
}

function extractSceneType(text) {
  if (text.toLowerCase().includes('indoor')) return 'indoor';
  if (text.toLowerCase().includes('outdoor')) return 'outdoor';
  if (text.toLowerCase().includes('int√©rieur')) return 'indoor';
  if (text.toLowerCase().includes('ext√©rieur')) return 'outdoor';
  return 'unknown';
}

function extractEnvironment(text) {
  // Logique simplifi√©e
  return text.substring(0, 100);
}

function extractTags(text) {
  // Logique simplifi√©e
  return [];
}

module.exports = { 
  analyzeScene, 
  analyzeScenesBatch,
  initializeOpenAI 
};

